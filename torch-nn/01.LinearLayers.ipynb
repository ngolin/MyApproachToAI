{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695d88b6",
   "metadata": {},
   "source": [
    "## Linear Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdceaf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94d1f8",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7142f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.Identity(): (*) -> (*)\n",
    "\"\"\"\n",
    "# https://docs.pytorch.org/docs/stable/generated/torch.nn.Identity.html\n",
    "\"\"\"Define Layer\"\"\"\n",
    "identity = nn.Identity()\n",
    "\n",
    "\"\"\"Forward Pass\"\"\"\n",
    "\n",
    "x = torch.randn(2, 3)\n",
    "y = identity(x)\n",
    "\n",
    "assert y.shape == x.shape\n",
    "assert torch.equal(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989bd47",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3a60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.Linear(\n",
    "    in_features=Hin,\n",
    "    out_features=Hout,\n",
    "):  (*, Hin)\n",
    "->  (*, Hout)\n",
    "\"\"\"\n",
    "# https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\"\"\"Define Layer\"\"\"\n",
    "\"\"\"1. Position Arguments\"\"\"\n",
    "in_features, out_features, bias = 2, 3, True\n",
    "\n",
    "linear = nn.Linear(\n",
    "    in_features,  # Hin, Required\n",
    "    out_features,  # Hout, Required\n",
    "    bias,  # default=True\n",
    "    device=None,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "\"\"\"Forward Pass\"\"\"\n",
    "\n",
    "batch_sizes = (2, 3, 4)\n",
    "\n",
    "x = torch.randn(*batch_sizes, in_features)  # (N, Hin)\n",
    "y = linear(x)\n",
    "\n",
    "assert y.shape == (*batch_sizes, out_features)  # (N, Hout)\n",
    "assert torch.allclose(y, F.linear(x, linear.weight, linear.bias))\n",
    "assert torch.allclose(\n",
    "    F.linear(x, linear.weight, linear.bias),\n",
    "    x @ linear.weight.t() + (linear.bias if bias else 0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010f8c9",
   "metadata": {},
   "source": [
    "### Bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae3ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.Bilinear(\n",
    "    in1_features=Hin1,\n",
    "    in2_features=Hin2,\n",
    "    out_features=Hout,\n",
    "):  (*, Hin1), (*, Hin2)\n",
    "->  (*, Hout)\n",
    "\"\"\"\n",
    "# https://docs.pytorch.org/docs/stable/generated/torch.nn.Bilinear.html\n",
    "\"\"\"Define Layer\"\"\"\n",
    "\"\"\"1. Position Arguments\"\"\"\n",
    "in1_features, in2_features, out_features, bias = 2, 3, 4, True\n",
    "\n",
    "bilinear = nn.Bilinear(\n",
    "    in1_features,  # Hin1, Required\n",
    "    in2_features,  # Hin2, Required\n",
    "    out_features,  # Hout, Required\n",
    "    bias,\n",
    "    device=None,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "\"\"\"Forward Pass\"\"\"\n",
    "batch_sizes = (2, 3, 4)\n",
    "\n",
    "x1 = torch.randn(*batch_sizes, in1_features)  # (N, Hin1)\n",
    "x2 = torch.randn(*batch_sizes, in2_features)  # (N, Hin2)\n",
    "y = bilinear(x1, x2)\n",
    "\n",
    "assert y.shape == (*batch_sizes, out_features)  # (N, Hout)\n",
    "assert torch.allclose(\n",
    "    y,\n",
    "    F.bilinear(x1, x2, bilinear.weight, bilinear.bias),\n",
    ")\n",
    "assert torch.allclose(\n",
    "    y,\n",
    "    torch.einsum(\"...i,kij,...j->...k\", x1, bilinear.weight, x2)\n",
    "    + (bilinear.bias if bias else 0),\n",
    "    atol=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92d4ce",
   "metadata": {},
   "source": [
    "### LazyLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ddc3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.LazyLinear(\n",
    "    out_features=Hout\n",
    "):  (*, Hin)\n",
    "->  (*, Hout)\n",
    "\"\"\"\n",
    "# https://docs.pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html\n",
    "\n",
    "\"\"\"Define Layer\"\"\"\n",
    "\"\"\"1. Position Arguments\"\"\"\n",
    "out_features, bias = 2, True\n",
    "\n",
    "lazy_linear = nn.LazyLinear(\n",
    "    out_features,  # Hout\n",
    "    bias,\n",
    "    device=None,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "\"\"\"Forward Pass\"\"\"\n",
    "\n",
    "batch_size, in_features = (3, 4), 5\n",
    "\n",
    "x = torch.randn(*batch_size, in_features)  # (N, Hin)\n",
    "y = lazy_linear(x)\n",
    "\n",
    "assert y.shape == (*batch_size, out_features)  # (N, Hout)\n",
    "assert torch.allclose(y, F.linear(x, lazy_linear.weight, lazy_linear.bias), atol=1e-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
